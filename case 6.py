import librosa
import numpy as np
import torch
from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer
from google.colab import files
import requests
import soundfile as sf

# 3Ô∏è‚É£ Function: Download a Proper Sample Audio (.wav)
def download_sample_audio():
    url = "https://github.com/Jakobovski/free-spoken-digit-dataset/raw/master/recordings/0_jackson_0.wav"
    r = requests.get(url)
    with open("sample.wav", "wb") as f:
        f.write(r.content)
    print("‚úÖ Sample audio file downloaded successfully: sample.wav")
    return "sample.wav"

# 4Ô∏è‚É£ Audio Preprocessing
def preprocess_audio(file_path):
    y, sr = librosa.load(file_path, sr=16000)  # Resample to 16kHz
    return y, sr

# 5Ô∏è‚É£ Load Pretrained Model (English)
model_name = "facebook/wav2vec2-base-960h"
tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)
model = Wav2Vec2ForCTC.from_pretrained(model_name)
model.eval()

# 6Ô∏è‚É£ Transcription Function
def transcribe_audio(file_path):
    y, sr = preprocess_audio(file_path)
    inputs = tokenizer(y, return_tensors="pt", padding="longest")

    with torch.no_grad():
        logits = model(input_values=inputs.input_values).logits

    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = tokenizer.batch_decode(predicted_ids)
    return transcription[0]

# 7Ô∏è‚É£ Choose File (Sample or Upload)
choice = input("Type 'sample' to use test audio or 'upload' to use your own file: ").strip().lower()

if choice == "sample":
    file_path = download_sample_audio()
else:
    print("üìÅ Please upload your .wav file")
    uploaded = files.upload()
    file_path = list(uploaded.keys())[0]

# 8Ô∏è‚É£ Run Transcription
print("\nüîç Processing audio...")
try:
    transcription = transcribe_audio(file_path)
    print("\nüó£Ô∏è Transcription:\n", transcription)
except Exception as e:
    print("\n‚ùå Error while processing audio:", e)
